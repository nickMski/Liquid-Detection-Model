{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d597bd",
   "metadata": {},
   "source": [
    "# MSOE AI-Club: Fall 2024 Innovation Lab Example Code\n",
    "**Innovation Labs Sponsor:** [Brady Corporation](https://www.bradyid.com/?s_kwcid=AL!10720!3!324787930987!e!!g!!brady%20corp&cid=ppc&camp=ppc-us-brand-google.com-search-trademark_exact-core-brady%20corp&gad_source=1&gbraid=0AAAAAD_q4Jq7FA-4zFdepNvtZEYWfDQG8&gclid=Cj0KCQjw05i4BhDiARIsAB_2wfDH78Ihm-CDyEXsvNKF8NpniM-tntM0M9wxCpCJmQ8ThIRQoFzUGhsaAmDdEALw_wcB)<br/>\n",
    "**Innovation Labs Rubric:** [Link to Official Rubric](https://msoe365-my.sharepoint.com/:w:/g/personal/paulsonb_msoe_edu/ERxEIGv5rMZDl78QqILSCLMBul3Q-D74qAjXg4iYWX4fiQ?e=BhT5lC)<br/>\n",
    "**Additional Computer Vision Learning Resources:** [Link to Learning Tree](https://msoe-maic.com/learning-tree?node=58)\n",
    "\n",
    "![IL Banner](https://raw.githubusercontent.com/24-25-Fall-Innovation-Lab/template/refs/heads/main/IL_Banner.png?token=GHSAT0AAAAAACYSMZ2Z6JVZBZYSQCFVG2L2ZYIASNQ)\n",
    "\n",
    "## Problem Statement\n",
    "Your challenge is to design an AI-based solution that can predict the amount of liquid in a container from a single image. While AI-Club has provided you with a baseline solution utilizing the **YOLOv8 segmentation algorithm**, your goal is to enhance and expand on this model, creating a more innovative and adaptable solution that can be applied across multiple use cases.\n",
    "\n",
    "<span style=\"color: #3A8DFF; font-weight: bold;\">New to AI?</span> No problem! Check out our ðŸŒ³ **Learning Tree** ðŸŒ³ for resources on [how to get started with programming](https://msoe-maic.com/learning-tree?node=2), [development environments](https://msoe-maic.com/learning-tree?node=10), [AI Basics](https://msoe-maic.com/learning-tree?node=19), and [Computer Vision](https://msoe-maic.com/learning-tree?node=58)!\n",
    "\n",
    "## What is YOLOv8?\n",
    "[YOLOv8](https://yolov8.com) is what we call a \"pre-trained\" model, meaning that it has already been trained on a large dataset of images. This allows the model to recognize patterns and objects in images that it has never seen before, similar to how [Chat-GPT](https://chatgpt.com) can answer questions that you prompt it which it may have never seen before. This is important in industry applications of AI because it allows companies to use AI to solve problems without having to spend the time and resources to train a model from scratch, ultimately saving time and money to create a solution -- such as in this hackathon!\n",
    "\n",
    "Since the model is pre-trained, we can simply download it from the web, as you'll see later in this example notebook. The application that this model was pre-trained on was object detection, meaning that it can recognize and locate objects in images. For this simplified example, we've basically fine-tuned the model to recognize the liquid in a container by determining the number of pixels in an image which are liquid and which are container, then dividing the two to get a percentage of liquid in the container.\n",
    "\n",
    "**Yolo V8 stands out in its capabilites to:**\n",
    "1. **Segment objects:** It creates pixel by pixel masks rather than similar object detection / bounding boxes. Similar models such as SAM (Segment Anything) have similar features.\n",
    "2. **Real-Time Inference:** Yolo is known for its fast inference speeds\n",
    "3. **High accuracy:** Yolo achieves high accuracy. Especially with the added ability in fine tuning the model, we're able to greatly increase the performance on a given dataset. \n",
    "\n",
    "## How to Use This Notebook\n",
    "This file (`ipynb`) is what's called a **Jupyter Notebook**. These types of files are commonly used by data scientists and AI engineers to write and run code in a way that is easy to read and understand -- often to determine the feasibility of a model or to test a model on a small dataset. Understanding this, you can run code cells with either `Shift+Enter` or `Ctrl+Enter` to see the output of the code. You can also edit the code in the cells to see how it affects the output.\n",
    "\n",
    "**Jupyter Notebooks** have a couple of additional useful features, most notably a `Code Block` and a `Markdown Block`. This allows you to seamlessly use both markdown (such as this cell) and run code. Variables are stored in memory between cells, allowing you to use data across the entire file. Additionally, the `Code Block` allows you to run terminal commands by prepending the line with `!`, such as the `!pip install` line below. There are even more capabilities possible, check out [this graphical cheatsheet](https://www.edureka.co/blog/wp-content/uploads/2018/10/Jupyter_Notebook_CheatSheet_Edureka.pdf) or [this guide](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to get really in depth!\n",
    "\n",
    "As for the compute power required to effectively run this notebook, this notebook is capable of running on your local machine (laptop) without much issue. However, the training process will likely take a long time to complete. <span style=\"color: red; font-weight: bold;\">Therefore, we propose that groups use either ROSIE (MSOE Students only) or Google Colab to train their models using NVIDIA T4 GPUs.</span>\n",
    "* [How to Run Jobs on ROSIE Supercomputer](https://msoe-maic.com/learning-tree?node=5)\n",
    "* [How to Use Google Colab](https://colab.research.google.com)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07e190",
   "metadata": {},
   "source": [
    "## Part 1: Import Statements And File Structure Setup\n",
    "Import statements are used to import libraries that are required to run the code. Libraries are collections of functions and methods that allow you to perform actions without having to write the code yourself. In this case, we are importing libraries that will allow us to work with images and data, as well as the YOLOv8 model.\n",
    "\n",
    "**Please Note:** If you are running locally on a Mac, you may need to use the command `pip3` as opposed to `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the required dependencies (libraries) for the project from the requirements.txt file\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e2ffdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from roboflow import Roboflow\n",
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Set HOME to get your current working directory\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME directory is set to:\", HOME)\n",
    "\n",
    "# Download the YOLO model\n",
    "%cd {HOME}\n",
    "!git clone https://github.com/ultralytics/ultralytics.git\n",
    "%cd {HOME}/ultralytics\n",
    "!pip install -e .\n",
    "\n",
    "# Clear the output to keep it clean\n",
    "clear_output()\n",
    "\n",
    "# Run checks for the YOLO model\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac502c8",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13752ed",
   "metadata": {},
   "source": [
    "## Part 2: Data Preprocessing\n",
    "One of the most important parts of dealing with AI algorithms is <span style=\"color: #3A8DFF; font-weight: bold;\">ensuring you have clean, well-structured, and A LOT of data</span>. In this case, we have a dataset of images that we will use to train our model. The data preprocessing step is where we will load in the data, clean it up, and prepare it for training.\n",
    "\n",
    "For this application, we're doing \"segmentation\", which is a part of [Computer Vision](https://msoe-maic.com/learning-tree?node=58) where we're trying to determine the boundaries of objects in an image. In this case, we're trying to determine the boundaries of the liquid in a container. Therefore, the data that we're using to train the model has specific outlines for where the boundaries of both the liquid and container are -- this way, the model can actually learn the difference between the two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14903c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading yolov8s-seg model and ensuring it is downloaded correctly\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(f'{HOME}/yolov8s-seg.pt')\n",
    "results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596f2dd",
   "metadata": {},
   "source": [
    "This cell will download all the data required to fine-tune this YOLOv8 model. Don't worry, we've already done the hard work of labeling the data for you!\n",
    "\n",
    "One parameter you may notice is `api_key`. We've setup this key for you to use Roboflow for free. If you'd like to use Roboflow for your own projects, you can sign up for a free account at [Roboflow](https://roboflow.com) -- it is best practice to use your own API keys for your own projects, as well as hiding them not as raw strings in your code. ðŸ‘€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ee499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making and moving into 'datasets' directory\n",
    "os.makedirs(f'{HOME}/datasets', exist_ok=True)\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "# Downloading `gradulated-flask-segmentation` dataset from Roboflow\n",
    "rf = Roboflow(api_key=\"ORjo88oQ6A7AwApZTU5e\")\n",
    "project = rf.workspace(\"university-msm2s\").project(\"graduated-flask-segmentation\")\n",
    "dataset = project.version(2).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec921272",
   "metadata": {},
   "source": [
    "When you're dealing with data for a machine learning model, you are often dealing with a `train`, `validation`, and `test` dataset. The `train` dataset is used to train the model, the `validation` dataset is used to validate the model's performance during training, and the `test` dataset is used to test the model's performance after training. This is important because it allows you to see how well the model is performing on data that it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a245840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for storing the data\n",
    "def calculate_next_folder(base_dir, base_name):\n",
    "    # List all directories in the base_dir\n",
    "    existing_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "    # Filter out directories that start with the base name (e.g., 'train')\n",
    "    dirs = [d for d in existing_dirs if d.startswith(base_name)]\n",
    "\n",
    "    # Find the highest number by extracting digits from directory names\n",
    "    nums = [int(d[len(base_name):]) for d in dirs if d[len(base_name):].isdigit()]\n",
    "\n",
    "    if base_name not in dirs:\n",
    "        return base_name\n",
    "    nums.append(1)\n",
    "    # Determine the next folder number\n",
    "    next_num = max(nums, default=1) + 1\n",
    "\n",
    "    # Return the new folder name\n",
    "    return f\"{base_name}{next_num}\"\n",
    "\n",
    "def get_next_folder(base_name):\n",
    "    base_dir_str =f'{HOME}/ultralytics/runs/segment/'\n",
    "    os.makedirs(base_dir_str, exist_ok=True)\n",
    "    base_dir = os.path.join(base_dir_str)\n",
    "    return calculate_next_folder(base_dir, base_name)\n",
    "\n",
    "train_folder_name = get_next_folder('train')\n",
    "predict_folder_name = get_next_folder('predict')\n",
    "val_folder_name = get_next_folder('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57276d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available (for NVIDIA GPUs) or MPS (for Apple Silicon Macs), and select the appropriate device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # use CUDA (NVIDIA GPU)\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")   # use MPS (Apple Silicon)\n",
    "    print(\"MPS is available. Using Apple Silicon GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # fallback to CPU\n",
    "    print(\"Neither CUDA nor MPS is available. Using CPU.\")\n",
    "\n",
    "train_folder_name = get_next_folder('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the data.yaml file to have the appropriate information about our dataset download\n",
    "file_path = '../datasets/Graduated-Flask-segmentation-2/data.yaml'\n",
    "\n",
    "# Open and load the YAML file\n",
    "with open(file_path, 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# Modify the 'train' and 'val' paths\n",
    "data['train'] = 'train/images'\n",
    "data['val'] = 'valid/images'\n",
    "\n",
    "# Save the updated YAML file\n",
    "with open(file_path, 'w') as file:\n",
    "    yaml.dump(data, file)\n",
    "\n",
    "print(\"YAML file updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ea1ed",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3c9fe",
   "metadata": {},
   "source": [
    "## Part 3: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3722644",
   "metadata": {},
   "source": [
    "<span style=\"color: gold; font-weight: bold;\">Now let's actually TRAIN our model! This is where the magic happens</span> ðŸŽ‰ <br/>\n",
    "This cell will train the model on the data that we just loaded in. The model will learn the patterns in the data and use that to make predictions on new data. This process is called \"fine-tuning\" because we are taking a model that has already been trained on a large dataset and training it on a smaller dataset to make it more accurate for a specific use case (in this case, determining the amount of liquid in a container).\n",
    "\n",
    "Please note, depending on the compute that you are using (laptop versus supercomputer), you should change the `epochs` accordingly. An `epoch` is a pass through the entire dataset for training, and an entire pass through is MUCH faster on a supercomputer compared to a laptop -- so typically, we reserve training for something like `1000 epochs` on a supercomputer, but only `10 epochs` on a laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457cc30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    data=f'{HOME}/datasets/Graduated-Flask-segmentation-2/data.yaml',  # Path to data.yaml\n",
    "    epochs=2,  # Number of epochs\n",
    "    imgsz=640,   # Image size\n",
    "    batch=16,    # Batch size\n",
    "    name=f'{train_folder_name}',  # Name for this training run\n",
    "    project=f'{HOME}/ultralytics/runs/segment',  # Save directory\n",
    "    workers=8,   # Number of workers for data loading\n",
    "    device=device  # Set the correct device (MPS, CUDA, or CPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04320c11",
   "metadata": {},
   "source": [
    "<span style=\"color: gold; font-weight: bold;\">If you've never trained an AI model before, you just made your first AI!</span> ðŸ¦¾ðŸ¤– <br/>\n",
    "This is a big deal! You've just trained a model to recognize the amount of liquid in a container from an image. This is a big step towards solving the problem that we've presented to you. Now, let's see how well it performs!\n",
    "\n",
    "<span style=\"color: red; font-weight: bold;\">Reminder:</span> The performance of this model will **greatly vary** depending on the `hyperparameters` you defined for the function `model.train`. Hyperparameters are the settings that you define for the model, such as the learning rate, batch size, and number of epochs. These settings can greatly affect the performance of the model, so it's important to experiment with different settings to see what works best for your specific use case! For getting decent results, I would recommend at least `30 epochs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ae449",
   "metadata": {},
   "source": [
    "We're going to be evaluating how well the model did on the `training data` portion of the dataset (the data it saw while `model.train()`). This is important because it allows us to see how well the model is learning the patterns in the data. If the model is performing well on the training data, then it is likely learning the patterns in the data well. However, if the model is not performing well on the training data, then it is likely not learning the patterns in the data well.\n",
    "\n",
    "Understanding this, if your model is not performing well on the training data, that is a sign that you may need to change the hyperparameters or the model architecture to better fit the data. This is because the main application of AI is to learn patterns in data and generalize to new data, so if the model is not learning the patterns in its own training data, then it will not be able to generalize to new data. <span style=\"color: #3A8DFF; font-weight: bold;\">Think of it like being a study guide that's the same as the exam but then still not passing the exam -- it's a sign that you need to study differently!</span> ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is going to showcase a confusion matrix for the trained model on the training dataset.\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model \n",
    "on a set of data for which the true values are known -- therefore, we're looking for diagonal values to be high.\n",
    "\"\"\"\n",
    "display(Image(filename=f\"{HOME}/ultralytics/runs/segment/{train_folder_name}/confusion_matrix.png\", width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e7fe2",
   "metadata": {},
   "source": [
    "Another important concept in machine learning is a situation called `overfitting`. Overfitting is when the model learns the patterns in the training data **too well** and is not able to generalize to new data. This is a common problem in machine learning and can be solved by using techniques such as [regularization](https://www.ibm.com/topics/regularization#:~:text=Regularization%20is%20a%20set%20of,for%20an%20increase%20in%20generalizability.), [dropout](https://towardsdatascience.com/dropout-in-neural-networks-47a162d621d9), and [early stopping](https://cyborgcodes.medium.com/what-is-early-stopping-in-deep-learning-eeb1e710a3cf). If you see that your model is performing well on the training data but not on the validation data, then it is likely overfitting to the training data. If the model is great at both, then it's likely a good model!\n",
    "\n",
    "<span style=\"color: red; font-weight: bold;\">Note:</span> Looking more specifically at the stats generated below, `loss` is a measure of how well the model is performing -- `loss` is the difference between the predicted value and the actual value. The lower the loss, the better the model is performing. Consequently, when training, you should see the loss decrease over time as the model learns the patterns in the data. If the loss is not decreasing, then the model is not learning the patterns in the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training process such as loss, precision, time, etc...\n",
    "display(Image(filename=f\"{HOME}/ultralytics/runs/segment/{train_folder_name}/results.png\", width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2d8b9",
   "metadata": {},
   "source": [
    "ðŸ“¸ **Now that we've seen how quantitatively well/bad the model is performing, let's actually see what the model is predicting!**\n",
    "\n",
    "Here is an example of what you could expect to output from the below `code cell`:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/24-25-Fall-Innovation-Lab/template/refs/heads/main/segmentation_example.png?token=GHSAT0AAAAAACYEXL3EW3KROJDOOHDBWRN2ZYID2LA\" alt=\"Segmentation Example\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results for the training data\n",
    "display(Image(filename=f\"{HOME}/ultralytics/runs/segment/{train_folder_name}/val_batch0_pred.jpg\", width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and the results\n",
    "model = YOLO(f'{HOME}/ultralytics/runs/segment/{train_folder_name}/weights/best.pt')\n",
    "save_dir = os.path.join(f'{HOME}/ultralytics/runs/segment', val_folder_name)\n",
    "val_folder_name = get_next_folder('val')\n",
    "model.val(data=f'{dataset.location}/data.yaml', save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073768d0",
   "metadata": {},
   "source": [
    "**Now let's do the same as we've done but just with the validation data!**<br/>\n",
    "`Validation Data` is data that the model has never seen before, so it's a good test to see how well the model is generalizing to new data. If the model is performing well on the validation data, then it is likely generalizing well to new data. If the model is not performing well on the validation data, then it is likely not generalizing well to new data. This is different from `testing data` because the model has never seen the validation data before, even with our review of it generalizing on the testing data after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ba66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results for the testing data (validation)\n",
    "display(Image(filename=f\"{HOME}/ultralytics/runs/segment/{val_folder_name}/confusion_matrix.png\", width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80255e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results for the testing data (validation)\n",
    "display(Image(filename=f\"{HOME}/ultralytics/runs/segment/{val_folder_name}/val_batch0_pred.jpg\", width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de9161",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0f6d3",
   "metadata": {},
   "source": [
    "## Part 4: Predicting the Percentage Filled on the Final Containers\n",
    "Now that we're satisfied with the model's performance on the `validation` and `training` datasets, let's predict on the test images and save the mask results along with the containers fill percentage\n",
    "\n",
    "Because this is a simple model, the **percentage filled** is simply calculated by the number of pixels in the liquid mask divided by the number of pixels in the overall container mask. This is a simple way to determine the percentage filled in the container, but it may not be the most accurate. In a real-world application, you may want to use a more complex model to determine the percentage filled in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions on the data you've reserved for testing\n",
    "predict_folder_name = get_next_folder('predict')\n",
    "\n",
    "# Inferencing with the model\n",
    "model_path = os.path.join(HOME, f\"ultralytics/runs/segment/{train_folder_name}/weights/best.pt\")\n",
    "source_path = os.path.join(dataset.location, \"test/images\")\n",
    "\n",
    "# Load the YOLO model from the trained weights\n",
    "model = YOLO(model_path)\n",
    "save_dir = os.path.join(f'{HOME}/ultralytics/runs/segment', predict_folder_name)\n",
    "# Run predictions on the test dataset\n",
    "results = model.predict(\n",
    "    source=source_path,  # Path to test images\n",
    "    conf=0.5,  # Confidence threshold\n",
    "    save=True,  # Save the predictions (output images)\n",
    "    save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e43d7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out images where Yolo couldn't find the desired masks, then combine masks for future calculations\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    if result.masks is None:\n",
    "        continue\n",
    "    \n",
    "    masks = result.masks.data\n",
    "    class_ids = result.boxes.cls\n",
    "    \n",
    "    flask_mask = None\n",
    "    liquid_mask = None\n",
    "\n",
    "    for mask_idx, mask in enumerate(masks):\n",
    "        mask_img = (mask.cpu().numpy() * 255).astype(np.uint8)\n",
    "        \n",
    "        class_id = int(class_ids[mask_idx].item())\n",
    "        class_name = class_names[class_id]\n",
    "\n",
    "        if class_name == 'graduated-flask':\n",
    "            flask_mask = mask_img\n",
    "        elif class_name == 'liquid-level-length':\n",
    "            liquid_mask = mask_img\n",
    "\n",
    "    # Ensure both masks are present.\n",
    "    if flask_mask is not None and liquid_mask is not None:\n",
    "        combined_mask = np.logical_or(flask_mask > 0, liquid_mask > 0).astype(np.uint8) * 255\n",
    "        \n",
    "        mask_dict[f'image_{idx + 1}'] = [flask_mask, liquid_mask, combined_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faeb2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you would like to save the masks for viewing. This cell is NOT needed to run the rest of the pipeline.\n",
    "temp_output_dir = os.path.join(HOME, \"mask_images\")\n",
    "os.makedirs(temp_output_dir, exist_ok=True)\n",
    "\n",
    "for image_name, masks in mask_dict.items():\n",
    "    flask_mask, liquid_mask, combined_mask = masks\n",
    "    \n",
    "    # flask mask\n",
    "    flask_mask_filename = os.path.join(temp_output_dir, f\"{image_name}_flask_mask.png\")\n",
    "    cv2.imwrite(flask_mask_filename, flask_mask)\n",
    "    print(f\"Flask mask saved to: {flask_mask_filename}\")\n",
    "    \n",
    "    # liquid-level-length mask\n",
    "    liquid_mask_filename = os.path.join(temp_output_dir, f\"{image_name}_liquid_mask.png\")\n",
    "    cv2.imwrite(liquid_mask_filename, liquid_mask)\n",
    "    print(f\"Liquid mask saved to: {liquid_mask_filename}\")\n",
    "    \n",
    "    # combined mask\n",
    "    combined_mask_filename = os.path.join(temp_output_dir, f\"{image_name}_combined_mask.png\")\n",
    "    cv2.imwrite(combined_mask_filename, combined_mask)\n",
    "    print(f\"Combined mask saved to: {combined_mask_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1fc295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the pixels and percentage filled on the final masks\n",
    "for image_name, masks in mask_dict.items():\n",
    "    flask_mask, liquid_mask, _ = masks  # Unpack the masks from the list\n",
    "    combined_mask = np.logical_or(flask_mask > 0, liquid_mask > 0).astype(np.uint8) * 255\n",
    "    \n",
    "    flask_area = np.sum(combined_mask == 255)  # Total white pixels in the combined mask\n",
    "    liquid_area = np.sum(liquid_mask == 255)   # Total white pixels in the liquid mask\n",
    "\n",
    "    if flask_area > 0:\n",
    "        percentage_filled = (liquid_area / flask_area) * 100\n",
    "    else:\n",
    "        percentage_filled = 0\n",
    "    \n",
    "    print(f\"{image_name}:\")\n",
    "    print(f\"  Combined mask (flask) white pixels: {flask_area}\")\n",
    "    print(f\"  Liquid mask white pixels: {liquid_area}\")\n",
    "    print(f\"  Percentage of flask filled with liquid: {percentage_filled:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa28dfcd",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672225c4",
   "metadata": {},
   "source": [
    "## Part 5: Make This Model Yours!\n",
    "<span style=\"color: gold; font-weight: bold;\">Congratulations!</span> <span style=\"color: #3A8DFF; font-weight: bold;\">Now that you've seen how to train a model to determine the amount of liquid in a container, it's time to make this model your own!</span> Here are some ideas to get you started:\n",
    "1. **Improve the Model:** Try different hyperparameters, model architectures, or training techniques to improve the performance of the model.\n",
    "2. **Expand the Model:** Try training the model on a larger dataset with more diverse images to see how well it generalizes to new data.\n",
    "3. **Create a New Model:** Try creating a new model from scratch to determine the amount of liquid in a container. You can use the [Learning Tree](https://msoe-maic.com/learning-tree?node=58) to learn more about how to create a new model.\n",
    "4. **Apply the Model:** Try applying the model to a new use case, such as determining the amount of liquid in a different type of container or determining the amount of liquid in a video stream.\n",
    "5. **And More!:** Don't limit your creativity to the ideas above! There are endless possibilities for how you can use AI to solve problems in the world!\n",
    "\n",
    "<span style=\"color: #3A8DFF; font-weight: bold;\">Happy coding!</span> ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
